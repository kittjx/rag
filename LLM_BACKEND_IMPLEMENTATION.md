# LLMåç«¯åˆ‡æ¢åŠŸèƒ½å®ç°æ€»ç»“

## ğŸ“‹ å®ç°æ¦‚è¿°

æœ¬æ¬¡æ›´æ–°ä¸ºç³»ç»Ÿæ·»åŠ äº†å®Œæ•´çš„å¤šLLMåç«¯æ”¯æŒï¼Œå…è®¸ç”¨æˆ·åœ¨DeepSeekã€Qwenã€OpenAIå’ŒOllamaä¹‹é—´çµæ´»åˆ‡æ¢ã€‚

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. ç»Ÿä¸€LLMæœåŠ¡ (`UnifiedLLMService`)

**æ–‡ä»¶**: `api/services/unified_llm_service.py`

#### ä¸»è¦ç‰¹æ€§:
- âœ… æ”¯æŒ4ç§LLMåç«¯: DeepSeek, Qwen, OpenAI, Ollama
- âœ… è‡ªåŠ¨æ£€æµ‹å¯ç”¨åç«¯
- âœ… æ™ºèƒ½æ•…éšœè½¬ç§»
- âœ… ç»Ÿä¸€çš„APIæ¥å£
- âœ… å¥åº·çŠ¶æ€ç›‘æ§

#### æ ¸å¿ƒæ–¹æ³•:

```python
class UnifiedLLMService:
    def __init__(self):
        # è‡ªåŠ¨æ£€æµ‹æœ€ä½³åç«¯
        
    async def generate(messages, temperature, max_tokens, stream):
        # ç»Ÿä¸€ç”Ÿæˆæ¥å£
        
    async def generate_with_context(question, context, system_prompt):
        # RAGä¸“ç”¨æ¥å£
        
    def switch_backend(backend):
        # æ‰‹åŠ¨åˆ‡æ¢åç«¯
        
    def auto_switch_on_failure():
        # è‡ªåŠ¨æ•…éšœè½¬ç§»
        
    def get_backend_info():
        # è·å–åç«¯ä¿¡æ¯
```

### 2. é…ç½®ç®¡ç†

**æ–‡ä»¶**: `config.py`

æ–°å¢é…ç½®é¡¹:
```python
# LLMåç«¯é€‰æ‹©
LLM_BACKEND = "auto"  # auto, deepseek, qwen, openai, ollama
USE_LOCAL_LLM = False

# DeepSeeké…ç½®
DEEPSEEK_API_KEY = "..."
DEEPSEEK_API_BASE = "..."
DEEPSEEK_MODEL = "deepseek-chat"

# Qwené…ç½®
QWEN_API_KEY = "..."
QWEN_API_BASE = "..."
QWEN_MODEL = "qwen-turbo"

# OpenAIé…ç½®
OPENAI_API_KEY = "..."
OPENAI_API_BASE = "..."
OPENAI_MODEL = "gpt-3.5-turbo"

# Ollamaé…ç½®
OLLAMA_BASE_URL = "http://localhost:11434"
OLLAMA_MODEL = "qwen2.5:7b"
```

### 3. APIç«¯ç‚¹

**æ–‡ä»¶**: `api/routers/system.py`

æ–°å¢ç«¯ç‚¹:

#### GET `/api/v1/system/version`
è·å–ç³»ç»Ÿç‰ˆæœ¬å’Œå½“å‰LLMåç«¯ä¿¡æ¯

å“åº”:
```json
{
  "llm_backend": "deepseek",
  "llm_model": "deepseek-chat"
}
```

#### GET `/api/v1/system/llm/backends`
è·å–æ‰€æœ‰åç«¯çŠ¶æ€

å“åº”:
```json
{
  "current_backend": "deepseek",
  "current_model": "deepseek-chat",
  "available_backends": [
    {
      "name": "deepseek",
      "model": "deepseek-chat",
      "healthy": true,
      "api_key_configured": true
    }
  ]
}
```

#### POST `/api/v1/system/llm/switch/{backend}`
åŠ¨æ€åˆ‡æ¢LLMåç«¯

è¯·æ±‚:
```bash
curl -X POST http://localhost:8000/api/v1/system/llm/switch/qwen
```

å“åº”:
```json
{
  "success": true,
  "message": "å·²åˆ‡æ¢åˆ° qwen åç«¯",
  "current_backend": "qwen",
  "current_model": "qwen-turbo"
}
```

### 4. è·¯ç”±æ›´æ–°

**æ–‡ä»¶**: `api/routers/chat.py`

- âœ… ä½¿ç”¨ `UnifiedLLMService` æ›¿ä»£ `DeepSeekService`
- âœ… ä¿æŒå‘åå…¼å®¹
- âœ… å“åº”ä¸­åŒ…å«åç«¯ä¿¡æ¯

## ğŸ“ æ–‡ä»¶å˜æ›´æ¸…å•

### æ–°å¢æ–‡ä»¶
1. `api/services/unified_llm_service.py` - ç»Ÿä¸€LLMæœåŠ¡
2. `.env.example` - ç¯å¢ƒå˜é‡ç¤ºä¾‹
3. `LLM_BACKENDS.md` - LLMåç«¯ä½¿ç”¨æŒ‡å—
4. `test_llm_backends.py` - LLMåç«¯æµ‹è¯•è„šæœ¬
5. `LLM_BACKEND_IMPLEMENTATION.md` - æœ¬æ–‡æ¡£

### ä¿®æ”¹æ–‡ä»¶
1. `config.py` - æ·»åŠ LLMåç«¯é…ç½®
2. `api/routers/chat.py` - ä½¿ç”¨UnifiedLLMService
3. `api/routers/system.py` - æ·»åŠ LLMåç«¯ç®¡ç†ç«¯ç‚¹
4. `README.md` - æ›´æ–°æ–‡æ¡£
5. `Makefile` - æ·»åŠ test-llmå‘½ä»¤

## ğŸ”„ åç«¯åˆ‡æ¢é€»è¾‘

### è‡ªåŠ¨æ£€æµ‹ä¼˜å…ˆçº§

```
1. å¦‚æœ USE_LOCAL_LLM=true
   â†’ ä½¿ç”¨ Ollama

2. å¦‚æœ LLM_BACKEND != "auto"
   â†’ ä½¿ç”¨æŒ‡å®šåç«¯

3. è‡ªåŠ¨æ£€æµ‹:
   a. æ£€æµ‹åˆ° DEEPSEEK_API_KEY â†’ DeepSeek
   b. æ£€æµ‹åˆ° QWEN_API_KEY â†’ Qwen
   c. æ£€æµ‹åˆ° OPENAI_API_KEY â†’ OpenAI
   d. é»˜è®¤ â†’ Ollama
```

### æ•…éšœè½¬ç§»

```
å½“å‰åç«¯è°ƒç”¨å¤±è´¥
  â†“
æ£€æŸ¥å…¶ä»–å¯ç”¨åç«¯
  â†“
åˆ‡æ¢åˆ°ç¬¬ä¸€ä¸ªå¯ç”¨åç«¯
  â†“
ç»§ç»­æœåŠ¡
```

## ğŸ§ª æµ‹è¯•

### è¿è¡Œæµ‹è¯•

```bash
# æµ‹è¯•LLMåç«¯
make test-llm

# æˆ–ç›´æ¥è¿è¡Œ
python test_llm_backends.py
```

### æµ‹è¯•å†…å®¹

1. âœ… ç‰ˆæœ¬ä¿¡æ¯è·å–
2. âœ… åç«¯çŠ¶æ€æŸ¥è¯¢
3. âœ… åç«¯åˆ‡æ¢
4. âœ… é—®ç­”åŠŸèƒ½

## ğŸ“Š æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FastAPI Application             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   UnifiedLLMService               â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚                                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚
â”‚  â”‚  â”‚ DeepSeek â”‚  â”‚   Qwen   â”‚     â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚
â”‚  â”‚                                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ â”‚
â”‚  â”‚  â”‚  OpenAI  â”‚  â”‚  Ollama  â”‚     â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚ â”‚
â”‚  â”‚                                   â”‚ â”‚
â”‚  â”‚  â€¢ Auto Detection                â”‚ â”‚
â”‚  â”‚  â€¢ Health Check                  â”‚ â”‚
â”‚  â”‚  â€¢ Failover                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: ä½¿ç”¨DeepSeek

```bash
# .env
LLM_BACKEND=deepseek
DEEPSEEK_API_KEY=sk-xxxxx
```

### ç¤ºä¾‹2: è‡ªåŠ¨æ£€æµ‹

```bash
# .env
LLM_BACKEND=auto
DEEPSEEK_API_KEY=sk-xxxxx
QWEN_API_KEY=sk-yyyyy
```

ç³»ç»Ÿä¼šä¼˜å…ˆä½¿ç”¨DeepSeek

### ç¤ºä¾‹3: æœ¬åœ°Ollama

```bash
# .env
USE_LOCAL_LLM=true
OLLAMA_MODEL=qwen2.5:7b
```

### ç¤ºä¾‹4: è¿è¡Œæ—¶åˆ‡æ¢

```bash
# å¯åŠ¨æ—¶ä½¿ç”¨DeepSeek
LLM_BACKEND=deepseek

# è¿è¡Œæ—¶åˆ‡æ¢åˆ°Qwen
curl -X POST http://localhost:8000/api/v1/system/llm/switch/qwen
```

## ğŸ¯ æœ€ä½³å®è·µ

### å¼€å‘ç¯å¢ƒ
```bash
USE_LOCAL_LLM=true
OLLAMA_MODEL=qwen2.5:7b
```
- èŠ‚çœAPIè´¹ç”¨
- å¿«é€Ÿè¿­ä»£

### æµ‹è¯•ç¯å¢ƒ
```bash
LLM_BACKEND=auto
DEEPSEEK_API_KEY=sk-xxxxx
QWEN_API_KEY=sk-yyyyy
```
- æµ‹è¯•å¤šåç«¯å…¼å®¹æ€§
- éªŒè¯æ•…éšœè½¬ç§»

### ç”Ÿäº§ç¯å¢ƒ
```bash
LLM_BACKEND=deepseek
DEEPSEEK_API_KEY=sk-xxxxx
QWEN_API_KEY=sk-yyyyy  # å¤‡ç”¨
```
- æ˜ç¡®æŒ‡å®šä¸»åç«¯
- é…ç½®å¤‡ç”¨åç«¯

## ğŸ” æ•…éšœæ’æŸ¥

### é—®é¢˜1: åç«¯ä¸å¯ç”¨

```bash
# æ£€æŸ¥åç«¯çŠ¶æ€
curl http://localhost:8000/api/v1/system/llm/backends

# æŸ¥çœ‹æ—¥å¿—
tail -f logs/api.log
```

### é—®é¢˜2: API Keyé”™è¯¯

æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„API Keyæ˜¯å¦æ­£ç¡®

### é—®é¢˜3: Ollamaè¿æ¥å¤±è´¥

```bash
# æ£€æŸ¥Ollamaæ˜¯å¦è¿è¡Œ
curl http://localhost:11434/api/tags

# å¯åŠ¨Ollama
ollama serve
```

## âœ… å®Œæˆæ¸…å•

- [x] å®ç°UnifiedLLMService
- [x] æ”¯æŒ4ç§LLMåç«¯
- [x] è‡ªåŠ¨æ£€æµ‹å’Œåˆ‡æ¢
- [x] æ•…éšœè½¬ç§»æœºåˆ¶
- [x] APIç«¯ç‚¹
- [x] é…ç½®ç®¡ç†
- [x] æ–‡æ¡£å®Œå–„
- [x] æµ‹è¯•è„šæœ¬
- [x] æ›´æ–°README

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [LLM_BACKENDS.md](LLM_BACKENDS.md) - è¯¦ç»†ä½¿ç”¨æŒ‡å—
- [README.md](README.md) - é¡¹ç›®æ€»è§ˆ
- [IMPROVEMENTS.md](IMPROVEMENTS.md) - æ”¹è¿›å†å²

## ğŸ‰ æ€»ç»“

æœ¬æ¬¡å®ç°ä¸ºç³»ç»Ÿæ·»åŠ äº†å®Œæ•´çš„å¤šLLMåç«¯æ”¯æŒï¼Œå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿:

1. **çµæ´»æ€§**: æ”¯æŒ4ç§ä¸»æµLLMåç«¯
2. **å¯é æ€§**: è‡ªåŠ¨æ•…éšœè½¬ç§»
3. **æ˜“ç”¨æ€§**: è‡ªåŠ¨æ£€æµ‹å’Œé…ç½®
4. **å¯æ‰©å±•æ€§**: æ˜“äºæ·»åŠ æ–°åç«¯
5. **å‘åå…¼å®¹**: ä¸å½±å“ç°æœ‰åŠŸèƒ½

ç”¨æˆ·ç°åœ¨å¯ä»¥æ ¹æ®éœ€æ±‚è‡ªç”±é€‰æ‹©å’Œåˆ‡æ¢LLMåç«¯ï¼Œå¤§å¤§æå‡äº†ç³»ç»Ÿçš„çµæ´»æ€§å’Œå¯ç”¨æ€§ï¼

