# 知识库问答系统 - Web界面

一个类似ChatGPT的现代化Web界面，用于与知识库进行智能问答。

## ✨ 特性

- 🎨 **现代化UI** - 类似ChatGPT的深色主题界面
- 💬 **实时对话** - 支持流式响应，实时显示AI回答
- 📚 **来源展示** - 显示答案的参考来源和相似度
- ⚙️ **灵活配置** - 可调整检索数量、温度等参数
- 🔄 **后端切换** - 支持动态切换LLM后端
- 📝 **对话历史** - 自动保存对话历史（本地存储）
- 📱 **响应式设计** - 支持桌面和移动设备

## 🚀 快速开始

### 1. 启动API服务

首先确保API服务正在运行：

```bash
# 在项目根目录
bash start.sh
# 或
make start
```

API服务将在 `http://localhost:8000` 启动

### 2. 启动Web界面

```bash
# 方法1: 使用启动脚本
bash start_web.sh

# 方法2: 使用Makefile
make web

# 方法3: 直接运行Python服务器
python3 serve_web.py
```

Web界面将在 `http://localhost:8080` 启动

### 3. 访问界面

在浏览器中打开: http://localhost:8080

## 📖 使用指南

### 基本使用

1. **提问**: 在底部输入框输入问题
2. **发送**: 点击发送按钮或按 `Ctrl+Enter`
3. **查看回答**: AI会实时流式返回答案
4. **查看来源**: 答案下方会显示参考来源

### 示例问题

点击欢迎页面的示例问题快速开始：
- "什么是健康的生活方式？"
- "如何保持良好的睡眠？"
- "运动对健康有什么好处？"

### 高级设置

点击右上角的 ⚙️ 图标打开设置面板：

#### 检索数量 (Top K)
- 范围: 1-10
- 默认: 5
- 说明: 从知识库检索的相关文档数量

#### 温度 (Temperature)
- 范围: 0-2
- 默认: 0.7
- 说明: 控制回答的随机性
  - 0: 最确定性的回答
  - 1: 平衡
  - 2: 最有创造性

#### 使用缓存
- 默认: 开启
- 说明: 缓存相同问题的答案，提升响应速度

#### 流式响应
- 默认: 开启
- 说明: 实时显示AI回答，类似ChatGPT
- 关闭后将等待完整答案后一次性显示

#### LLM后端
- 选项: DeepSeek, Qwen, OpenAI, Ollama
- 说明: 选择使用的大语言模型后端
- 只显示已配置且可用的后端

### 对话管理

#### 新建对话
点击左侧边栏的 "➕ 新对话" 按钮

#### 对话历史
- 自动保存最近20条对话
- 点击历史记录可查看（当前版本仅显示标题）
- 历史记录保存在浏览器本地存储

## 🎨 界面说明

### 布局

```
┌─────────────┬──────────────────────────────┐
│             │        顶部栏                │
│   侧边栏    ├──────────────────────────────┤
│             │                              │
│  - 新对话   │      消息区域                │
│  - 历史     │                              │
│  - 系统信息 │                              │
│             ├──────────────────────────────┤
│             │      输入区域                │
└─────────────┴──────────────────────────────┘
```

### 侧边栏
- **新对话按钮**: 开始新的对话
- **对话历史**: 显示最近的对话
- **系统信息**: 显示当前使用的LLM后端和模型

### 消息区域
- **用户消息**: 深色背景，👤 头像
- **AI消息**: 稍浅背景，🤖 头像
- **参考来源**: 显示在AI回答下方，包含：
  - 来源序号和相似度
  - 文本片段
  - 文件名

### 输入区域
- **文本框**: 自动调整高度
- **发送按钮**: 📤 图标
- **快捷键**: `Ctrl+Enter` 发送

## 🔧 技术栈

- **HTML5** - 结构
- **CSS3** - 样式（深色主题）
- **Vanilla JavaScript** - 交互逻辑
- **Fetch API** - HTTP请求
- **Server-Sent Events (SSE)** - 流式响应
- **LocalStorage** - 本地数据存储

## 📁 文件结构

```
web/
├── index.html      # 主页面
├── style.css       # 样式表
├── app.js          # JavaScript逻辑
└── README.md       # 本文档
```

## 🎯 特色功能

### 1. 流式响应

类似ChatGPT，AI回答会逐字显示：

```javascript
// 使用Server-Sent Events实现
const response = await fetch('/api/v1/chat/stream', {
    method: 'POST',
    body: JSON.stringify({...})
});

const reader = response.body.getReader();
// 逐块读取并显示
```

### 2. 智能来源展示

每个回答都会显示参考来源：
- 📊 相似度评分
- 📄 文档片段
- 📁 文件名

### 3. 响应式设计

自动适配不同屏幕尺寸：
- 桌面: 侧边栏 + 主区域
- 移动: 可折叠侧边栏

### 4. 本地存储

对话历史保存在浏览器：
```javascript
localStorage.setItem('chatHistory', JSON.stringify(history));
```

## 🔍 故障排查

### 问题1: 无法连接到API

**症状**: 页面显示"加载中..."或请求失败

**解决方案**:
1. 检查API服务是否运行: `curl http://localhost:8000/health`
2. 确认API端口是8000
3. 检查浏览器控制台的错误信息

### 问题2: CORS错误

**症状**: 浏览器控制台显示CORS错误

**解决方案**:
API已配置允许所有来源，如果仍有问题：
1. 检查 `api/main.py` 中的CORS配置
2. 确保使用 `http://localhost:8080` 而不是 `file://`

### 问题3: 流式响应不工作

**症状**: 回答不是逐字显示

**解决方案**:
1. 检查设置中"流式响应"是否开启
2. 检查浏览器是否支持Fetch API和ReadableStream
3. 查看浏览器控制台的错误信息

### 问题4: 对话历史丢失

**症状**: 刷新页面后历史记录消失

**解决方案**:
- 对话历史保存在浏览器LocalStorage
- 清除浏览器数据会删除历史
- 使用隐私模式可能不保存历史

## 🚀 性能优化

### 已实现
- ✅ 流式响应减少等待时间
- ✅ 缓存机制提升重复查询速度
- ✅ GZip压缩减少传输大小
- ✅ 本地存储减少服务器请求

### 可扩展
- 虚拟滚动处理大量消息
- Service Worker离线支持
- WebSocket替代SSE
- 消息分页加载

## 📝 开发说明

### 修改API地址

编辑 `app.js` 第2行：

```javascript
const API_BASE_URL = 'http://localhost:8000';
```

### 修改Web端口

编辑 `serve_web.py` 第10行：

```python
PORT = 8080
```

### 自定义主题

编辑 `style.css` 中的CSS变量：

```css
:root {
    --primary-color: #10a37f;
    --bg-color: #343541;
    /* ... */
}
```

## 🎉 总结

这是一个功能完整的ChatGPT风格Web界面，提供：
- 🎨 美观的用户界面
- 💬 流畅的对话体验
- 📚 智能的知识检索
- ⚙️ 灵活的配置选项

享受与知识库的智能对话吧！🚀

